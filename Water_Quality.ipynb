{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3c9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6a24a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cedc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, optimizer, fields, targets):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    predictions = model(fields)\n",
    "\n",
    "    loss = loss_function(predictions, targets.float())\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def predict(model, fields):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if not isinstance(fields, torch.Tensor):\n",
    "\n",
    "            fields = torch.tensor(fields)\n",
    "\n",
    "        predictions = model(fields).numpy()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def batch_predict(model, data_loader):\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "\n",
    "    for fields, target in data_loader:\n",
    "\n",
    "        prediction = predict(model, fields)\n",
    "\n",
    "        targets.extend(target.tolist())\n",
    "        predictions.extend(prediction.tolist())\n",
    "\n",
    "    score = r2_score(targets, predictions)\n",
    "\n",
    "    return predictions, score\n",
    "\n",
    "\n",
    "def train(x_train, y_train, \n",
    "          x_test, y_test, \n",
    "          model,\n",
    "          epochs=50,\n",
    "          batch_size=8,\n",
    "          learning_rate=0.001, \n",
    "          weight_decay=1e-6,\n",
    "          printout_period=1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    records_count = len(x_train)\n",
    "\n",
    "    batches = records_count // batch_size\n",
    "    \n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), \n",
    "                                 lr=learning_rate,\n",
    "                                 weight_decay=weight_decay)\n",
    "    \n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        list(zip(x_train, y_train)), \n",
    "        batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    \n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        list(zip(x_test, y_test)), \n",
    "        batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    \n",
    "    best_model = model\n",
    "    best_avg_train_loss = 0\n",
    "    best_avg_test_loss = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "        \n",
    "    total_records_count = epochs * records_count\n",
    "    \n",
    "    fit_batch_tracker = tqdm.trange(\n",
    "        total_records_count,\n",
    "        unit=' records',\n",
    "        unit_scale=True,\n",
    "        ncols=90,\n",
    "        mininterval=1\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        fit_batch_tracker.set_description(f\"Epoch: {epoch + 1}\")\n",
    "               \n",
    "        epoch_train_loss = 0\n",
    "        \n",
    "        for xs, ys in data_loader_train:\n",
    "                   \n",
    "            loss_evaluated = fit(model, loss_function, optimizer, xs, ys)\n",
    "            \n",
    "            epoch_train_loss += loss_evaluated\n",
    "            \n",
    "            fit_batch_tracker.update(batch_size)\n",
    "\n",
    "            predictions = predict(model, xs)\n",
    "            \n",
    "        \n",
    "        predictions, r2_train = batch_predict(model, data_loader_test)\n",
    "        \n",
    "        print(\"r2_train:\", r2_train)\n",
    "\n",
    "        # fit_batch_tracker.set_postfix(r2=f\"{r2_train:.02f}\")\n",
    "            \n",
    "        avg_train_loss = epoch_train_loss / batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Test\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        epoch_test_loss = 0\n",
    "        \n",
    "        for xs, ys in data_loader_test:\n",
    "            \n",
    "            loss_evaluated = loss_function(model(xs), ys)\n",
    "            epoch_test_loss += loss_evaluated\n",
    "            \n",
    "        avg_test_loss = epoch_test_loss / batches\n",
    "        \n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        predictions, r2_test = batch_predict(model, data_loader_test)\n",
    "        \n",
    "        print(\"r2_test:\", r2_test)\n",
    "        \n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_avg_test_loss = avg_test_loss\n",
    "            \n",
    "        if avg_test_loss < best_avg_test_loss:\n",
    "            best_avg_test_loss = avg_test_loss\n",
    "            best_model = model\n",
    "            \n",
    "        # if not epoch % printout_period:\n",
    "        #     print(\"Average train loss over epoch {}: {:.4f}\".format(epoch, avg_train_loss))\n",
    "        #     print(\"Average test loss over epoch {}: {:.4f}\\n\".format(epoch, avg_test_loss))\n",
    "    \n",
    "    print(f\"Best train loss: {min(train_losses):.02f}\")\n",
    "    print(f\"Best test loss: {best_avg_test_loss:.02f}\")\n",
    "    print(f\"Train time: {time.time() - start_time:.02f} seconds\")\n",
    "    \n",
    "    return best_model, (torch.tensor(train_losses), torch.tensor(test_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bbfbe",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75d4b0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('water_potability.csv')\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c7ae59e-455e-4451-83f3-fb2bb6b3707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.584087</td>\n",
       "      <td>188.313324</td>\n",
       "      <td>28748.687739</td>\n",
       "      <td>7.544869</td>\n",
       "      <td>326.678363</td>\n",
       "      <td>280.467916</td>\n",
       "      <td>8.399735</td>\n",
       "      <td>54.917862</td>\n",
       "      <td>2.559708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.223862</td>\n",
       "      <td>248.071735</td>\n",
       "      <td>28749.716544</td>\n",
       "      <td>7.513408</td>\n",
       "      <td>393.663396</td>\n",
       "      <td>283.651634</td>\n",
       "      <td>13.789695</td>\n",
       "      <td>84.603556</td>\n",
       "      <td>2.672989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.635849</td>\n",
       "      <td>203.361523</td>\n",
       "      <td>13672.091764</td>\n",
       "      <td>4.563009</td>\n",
       "      <td>303.309771</td>\n",
       "      <td>474.607645</td>\n",
       "      <td>12.363817</td>\n",
       "      <td>62.798309</td>\n",
       "      <td>4.401425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
       "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
       "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  \n",
       "5        8.399735        54.917862   2.559708           0  \n",
       "6       13.789695        84.603556   2.672989           0  \n",
       "7       12.363817        62.798309   4.401425           0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4e73b6d-fc29-44b3-8bc4-ebd33cafeb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782466</td>\n",
       "      <td>0.564114</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.583804</td>\n",
       "      <td>0.574378</td>\n",
       "      <td>-0.783962</td>\n",
       "      <td>1.227032</td>\n",
       "      <td>2.111652</td>\n",
       "      <td>0.844761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.275463</td>\n",
       "      <td>-0.455653</td>\n",
       "      <td>-0.455835</td>\n",
       "      <td>-0.370947</td>\n",
       "      <td>-0.560480</td>\n",
       "      <td>-0.348429</td>\n",
       "      <td>-0.842154</td>\n",
       "      <td>-2.140399</td>\n",
       "      <td>0.135033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.954835</td>\n",
       "      <td>-0.234614</td>\n",
       "      <td>0.790645</td>\n",
       "      <td>0.259104</td>\n",
       "      <td>-0.158911</td>\n",
       "      <td>-1.810063</td>\n",
       "      <td>-1.792340</td>\n",
       "      <td>-0.714423</td>\n",
       "      <td>-1.807366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.994902</td>\n",
       "      <td>1.596951</td>\n",
       "      <td>0.790764</td>\n",
       "      <td>0.239248</td>\n",
       "      <td>1.467140</td>\n",
       "      <td>-1.770608</td>\n",
       "      <td>-0.170876</td>\n",
       "      <td>1.132494</td>\n",
       "      <td>-1.662163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.985323</td>\n",
       "      <td>0.226606</td>\n",
       "      <td>-0.954313</td>\n",
       "      <td>-1.622878</td>\n",
       "      <td>-0.726179</td>\n",
       "      <td>0.595858</td>\n",
       "      <td>-0.599824</td>\n",
       "      <td>-0.224135</td>\n",
       "      <td>0.553348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "3  0.782466  0.564114  0.011687     0.583804  0.574378     -0.783962   \n",
       "4  1.275463 -0.455653 -0.455835    -0.370947 -0.560480     -0.348429   \n",
       "5 -0.954835 -0.234614  0.790645     0.259104 -0.158911     -1.810063   \n",
       "6  1.994902  1.596951  0.790764     0.239248  1.467140     -1.770608   \n",
       "7  0.985323  0.226606 -0.954313    -1.622878 -0.726179      0.595858   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "3        1.227032         2.111652   0.844761           0  \n",
       "4       -0.842154        -2.140399   0.135033           0  \n",
       "5       -1.792340        -0.714423  -1.807366           0  \n",
       "6       -0.170876         1.132494  -1.662163           0  \n",
       "7       -0.599824        -0.224135   0.553348           0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "FEATURE_COLUMNS = data.columns[:-1]\n",
    "\n",
    "scaled_features = standard_scaler.fit_transform(data[FEATURE_COLUMNS])\n",
    "\n",
    "data[FEATURE_COLUMNS] = scaled_features\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c43dcd-6bc5-4bd5-9bce-849ec346fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 1407 604\n"
     ]
    }
   ],
   "source": [
    "DATA_LIMIT = 2011\n",
    "\n",
    "limited_data = data[:DATA_LIMIT].copy()\n",
    "\n",
    "train_length = int(len(limited_data) * 0.7)\n",
    "\n",
    "data_train = limited_data[:train_length].copy()\n",
    "data_test = limited_data[train_length:].copy()\n",
    "\n",
    "print(len(limited_data), len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fda6a6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05f19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "q_delta = 0.01\n",
    "q_depth = 1\n",
    "\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights):\n",
    "    for idx in range(n_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "    for idx, element in enumerate(q_input_features):\n",
    "        qml.RY(element, wires=idx)\n",
    "    for k in range(q_depth):\n",
    "        for i in range(0, n_qubits - 1, 2):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "        for i in range(1, n_qubits - 1, 2):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "        for idx, element in enumerate(q_weights):\n",
    "            qml.RY(element, wires=idx)\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return exp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20438bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features):\n",
    "        super(DressedQuantumNet, self).__init__()\n",
    "        self.pre_net = nn.Linear(n_features, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, n_features)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = pre_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_inputs=1, hidden=32):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden)\n",
    "        # self.fc2 = nn.Linear(hidden, hidden)\n",
    "        # self.fc3 = nn.Linear(hidden, hidden)\n",
    "        # self.fc4 = nn.Linear(hidden, hidden)\n",
    "        self.dressed = DressedQuantumNet(hidden)\n",
    "        self.fc6 = nn.Linear(hidden, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.num_inputs = x.shape[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.dressed(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        # x = F.sigmoid(x)\n",
    "        \n",
    "        # print(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11c422b-7dfe-4189-b87c-411ebee293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalModel(nn.Module):\n",
    "    def __init__(self, num_inputs=1, hidden=32):\n",
    "        super(ClassicalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, hidden)\n",
    "        self.fc5 = nn.Linear(hidden, hidden)\n",
    "        self.fc6 = nn.Linear(hidden, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.num_inputs = x.shape[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        # x = F.softmax(x, dim=1)\n",
    "        # x = F.sigmoid(x)\n",
    "        \n",
    "        # print(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a75da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4 input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5ce097-4b54-443b-b483-e926ea9b6588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = data_train.columns[:-1]\n",
    "\n",
    "# FEATURE_COLUMNS = ['Hardness', 'Solids', 'Chloramines', 'Conductivity'] \n",
    "                   # 'Organic_carbon', 'Turbidity']\n",
    "LABEL_COLUMN = ['Potability']\n",
    "\n",
    "x_train = torch.tensor(data_train[FEATURE_COLUMNS].values).float()\n",
    "y_train = torch.tensor(data_train[LABEL_COLUMN].values).float()\n",
    "\n",
    "x_test = torch.tensor(data_test[FEATURE_COLUMNS].values).float()\n",
    "y_test = torch.tensor(data_test[LABEL_COLUMN].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683b9df9-aed6-432e-b264-a76601646f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_inputs = x_train.shape[1]\n",
    "\n",
    "# model = Model(num_inputs=num_inputs)\n",
    "\n",
    "model = ClassicalModel(num_inputs=num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4883ebe8-c8f9-4362-8d7e-af1d7932770b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████████████████████████▊| 1.40k/1.41k [00:00<00:00, 4.62k records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train: -0.15776428677827603\n",
      "r2_test: -0.1596204560989023\n",
      "Best train loss: 2.11\n",
      "Best test loss: 0.12\n",
      "Train time: 0.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model, loss = train(x_train, y_train, \n",
    "                            x_test, y_test,\n",
    "                            model=model,\n",
    "                            batch_size=8,\n",
    "                            epochs=1, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022c8fcd-07aa-404a-b321-14e28ddf78e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss[0], label=\"Train Loss\")\n",
    "plt.plot(loss[1], label=\"Test Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfd96007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.005552053451538086 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49912837], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "y_pred = trained_model(x_train)\n",
    "\n",
    "prediction = y_pred.detach().numpy()\n",
    "\n",
    "print(\"Time: %s seconds\" % (time.time() - start_time))\n",
    "\n",
    "data_train.head()\n",
    "\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5af91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train.to_csv('hybrid_nn_dqc_train.csv', index=False)\n",
    "# data_test.to_csv('hybrid_nn_dqc_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8b848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.106091</td>\n",
       "      <td>0.123841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  test_loss\n",
       "0    2.106091   0.123841"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_data = pd.DataFrame()\n",
    "loss_data['train_loss'] = loss[0]\n",
    "loss_data['test_loss'] = loss[1]\n",
    "loss_data.to_csv('hybrid_nn_dqc_loss.csv', index=False)\n",
    "loss_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227025dd-8547-4c90-9135-0f133b9066a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70f715c7-e958-4235-887d-df27ab002d7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6126cf40-0150-403b-bde0-7473599be75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prices(data_train, data_test, title='train'):\n",
    "    \n",
    "    data_train = data_train.sort_values('initial_stock_price')\n",
    "    data_test = data_test.sort_values('initial_stock_price')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    axs[0].scatter(data_train['initial_stock_price'], data_train['option_price'], s=4, c='b', \n",
    "                label='Monte-Carlo')\n",
    "    axs[0].scatter(data_train['initial_stock_price'], data_train['predicted_option_price'], s=4, c='r',\n",
    "                label='Model')\n",
    "    axs[0].set_title('Train')\n",
    "    axs[1].scatter(data_test['initial_stock_price'], data_test['option_price'], s=4, c='b', \n",
    "                label='Monte-Carlo')\n",
    "    axs[1].scatter(data_test['initial_stock_price'], data_test['predicted_option_price'], s=4, c='r',\n",
    "                label='Model')\n",
    "    axs[1].set_title('Test')\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='initial stock price', ylabel='option price')\n",
    "        ax.label_outer()\n",
    "    plt.savefig(title+'.png', facecolor='white', dpi=150)\n",
    "\n",
    "    \n",
    "def plot_loss(loss, title='train'):\n",
    "    \n",
    "    train_loss, test_loss = loss[0], loss[1]\n",
    "    epochs = [i for i in range(len(train_loss))]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    axs[0].plot(epochs, train_loss, c='b')\n",
    "    axs[0].set_title('Train')\n",
    "    axs[1].plot(epochs, test_loss, c='b')\n",
    "    axs[1].set_title('Test')\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='epoch', ylabel='loss')\n",
    "        ax.label_outer()\n",
    "    plt.savefig(title+'.png', facecolor='white', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c58cd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(loss, 'hybrid_nn_dqc_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89bed7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_stock_prices(data_train, data_test, title='hybrid_nn_dqc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4cdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
